{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 1.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming assignment you will be working with `1C` dataset from the final competition. You are asked to encode `item_id` in 4 different ways:\n",
    "\n",
    "    1) Via KFold scheme;  \n",
    "    2) Via Leave-one-out scheme;\n",
    "    3) Via smoothing scheme;\n",
    "    4) Via expanding mean scheme.\n",
    "\n",
    "**You will need to submit** the correlation coefficient between resulting encoding and target variable up to 4 decimal places.\n",
    "\n",
    "### General tips\n",
    "\n",
    "* Fill NANs in the encoding with `0.3343`.\n",
    "* Some encoding schemes depend on sorting order, so in order to avoid confusion, please use the following code snippet to construct the data frame. This snippet also implements mean encoding without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from grader import Grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv('../readonly/final_project_data/sales_train.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the competition task is to make a monthly prediction, we need to aggregate the data to montly level before doing any encodings. The following code-cell serves just that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/groupby.py:4036: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales[sales['date_block_num']==block_num]['shop_id'].unique()\n",
    "    cur_items = sales[sales['date_block_num']==block_num]['item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "#turn the grid into pandas dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "#get aggregated values for (shop_id, item_id, month)\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':{'target':'sum'}})\n",
    "\n",
    "#fix column names\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "#join aggregated data to the grid\n",
    "all_data = pd.merge(grid,gb,how='left',on=index_cols).fillna(0)\n",
    "#sort the data\n",
    "all_data.sort_values(['date_block_num','shop_id','item_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1609119</th>\n",
       "      <td>59</td>\n",
       "      <td>22164</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609120</th>\n",
       "      <td>59</td>\n",
       "      <td>22164</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609121</th>\n",
       "      <td>59</td>\n",
       "      <td>22167</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609122</th>\n",
       "      <td>59</td>\n",
       "      <td>22167</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609123</th>\n",
       "      <td>59</td>\n",
       "      <td>22167</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         shop_id  item_id  date_block_num  target\n",
       "1609119       59    22164              27     2.0\n",
       "1609120       59    22164              30     1.0\n",
       "1609121       59    22167               9     1.0\n",
       "1609122       59    22167              11     2.0\n",
       "1609123       59    22167              17     1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2935844</th>\n",
       "      <td>10.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935845</th>\n",
       "      <td>09.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935846</th>\n",
       "      <td>14.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7459</td>\n",
       "      <td>349.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935847</th>\n",
       "      <td>22.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7440</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935848</th>\n",
       "      <td>03.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  date_block_num  shop_id  item_id  item_price  \\\n",
       "2935844  10.10.2015              33       25     7409       299.0   \n",
       "2935845  09.10.2015              33       25     7460       299.0   \n",
       "2935846  14.10.2015              33       25     7459       349.0   \n",
       "2935847  22.10.2015              33       25     7440       299.0   \n",
       "2935848  03.10.2015              33       25     7460       299.0   \n",
       "\n",
       "         item_cnt_day  \n",
       "2935844           1.0  \n",
       "2935845           1.0  \n",
       "2935846           1.0  \n",
       "2935847           1.0  \n",
       "2935848           1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10913850, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean encodings without regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we did the techinical work, we are ready to actually *mean encode* the desired `item_id` variable. \n",
    "\n",
    "Here are two ways to implement mean encoding features *without* any regularization. You can use this code as a starting point to implement regularized techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id\n",
      "0        0.020000\n",
      "1        0.023810\n",
      "2        0.019802\n",
      "3        0.019802\n",
      "4        0.020000\n",
      "5        0.020000\n",
      "6        0.020000\n",
      "7        0.020000\n",
      "8        0.019802\n",
      "9        0.019608\n",
      "10       0.020000\n",
      "11       0.020000\n",
      "12       0.021739\n",
      "13       0.020000\n",
      "14       0.020000\n",
      "15       0.020000\n",
      "16       0.020000\n",
      "17       0.020000\n",
      "18       0.019608\n",
      "19       0.022222\n",
      "20       0.019608\n",
      "21       0.020000\n",
      "22       0.021277\n",
      "23       0.021277\n",
      "24       0.021277\n",
      "25       0.019608\n",
      "26       0.019231\n",
      "27       0.056834\n",
      "28       0.141176\n",
      "29       0.037383\n",
      "           ...   \n",
      "22140    0.191461\n",
      "22141    0.276042\n",
      "22142    0.069930\n",
      "22143    1.930804\n",
      "22144    0.266667\n",
      "22145    0.650407\n",
      "22146    0.040334\n",
      "22147    0.082100\n",
      "22148    0.021739\n",
      "22149    0.058923\n",
      "22150    0.088821\n",
      "22151    1.159375\n",
      "22152    0.155109\n",
      "22153    0.026627\n",
      "22154    0.109870\n",
      "22155    0.093671\n",
      "22156    0.029197\n",
      "22157    0.021978\n",
      "22158    0.022727\n",
      "22159    0.172414\n",
      "22160    0.097030\n",
      "22161    0.022222\n",
      "22162    1.556793\n",
      "22163    0.581395\n",
      "22164    1.235589\n",
      "22165    0.021277\n",
      "22166    0.295918\n",
      "22167    1.081081\n",
      "22168    0.032967\n",
      "22169    0.020833\n",
      "Name: target, Length: 21807, dtype: float64\n",
      "0.483038698862\n"
     ]
    }
   ],
   "source": [
    "# Calculate a mapping: {item_id: target_mean}\n",
    "item_id_target_mean = all_data.groupby('item_id').target.mean()\n",
    "print(item_id_target_mean)\n",
    "# In our non-regularized case we just *map* the computed means to the `item_id`'s\n",
    "all_data['item_target_enc'] = all_data['item_id'].map(item_id_target_mean)\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) \n",
    "\n",
    "# Print correlation between target values and predicted values.\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.483038698862\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "     Differently to `.target.mean()` function `transform` \n",
    "   will return a dataframe with an index like in `all_data`.\n",
    "   Basically this single line of code is equivalent to the first two lines from of Method 1.\n",
    "'''\n",
    "all_data['item_target_enc'] = all_data.groupby('item_id')['target'].transform('mean')\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) \n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the printed value? It is the correlation coefficient between the target variable and your new encoded feature. You need to **compute correlation coefficient** between the encodings, that you will implement and **submit those to coursera**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grader = Grader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KFold scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explained starting at 41 sec of [Regularization video](https://www.coursera.org/learn/competitive-data-science/lecture/LGYQ2/regularization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now it's your turn to write the code!** \n",
    "\n",
    "You may use 'Regularization' video as a reference for all further tasks.\n",
    "\n",
    "First, implement KFold scheme with five folds. Use KFold(5) from sklearn.model_selection. \n",
    "\n",
    "1. Split your data in 5 folds with `sklearn.model_selection.KFold` with `shuffle=False` argument.\n",
    "2. Iterate through folds: use all but the current fold to calculate mean target for each level `item_id`, and  fill the current fold.\n",
    "\n",
    "    *  See the **Method 1** from the example implementation. In particular learn what `map` and pd.Series.map functions do. They are pretty handy in many situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20205,)\n",
      "(21289,)\n",
      "(21521,)\n",
      "(21416,)\n",
      "(19244,)\n",
      "0.41645907128\n",
      "Current answer for task KFold_scheme is: 0.41645907128\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\\\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "skf = KFold(shuffle=False, n_splits = 5)\n",
    "\n",
    "for train_index, val_index in skf.split(all_data):\n",
    "    x_tr = all_data.iloc[train_index]\n",
    "    #get mean of target of each item_id in training set\n",
    "    mean = x_tr.groupby(\"item_id\").target.mean()\n",
    "    print(mean.shape)\n",
    "    # map = outer join. join 2 series(columns) by mapping the id.\n",
    "    all_data.loc[all_data.index[val_index],'item_target_enc'] = all_data.loc[all_data.index[val_index],'item_id'].map(mean)\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) \n",
    "# You will need to compute correlation like that\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)\n",
    "grader.submit_tag('KFold_scheme', corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2182770,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.loc[all_data.index[val_index],'item_id'].map(mean).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Leave-one-out scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, implement leave-one-out scheme. Note that if you just simply set the number of folds to the number of samples and run the code from the **KFold scheme**, you will probably wait for a very long time. \n",
    "\n",
    "To implement a faster version, note, that to calculate mean target value using all the objects but one *given object*, you can:\n",
    "\n",
    "1. Calculate sum of the target values using all the objects.\n",
    "2. Then subtract the target of the *given object* and divide the resulting value by `n_objects - 1`. \n",
    "\n",
    "Note that you do not need to perform `1.` for every object. And `2.` can be implemented without any `for` loop.\n",
    "\n",
    "It is the most convenient to use `.transform` function as in **Method 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.480384831129\n",
      "Current answer for task Leave-one-out_scheme is: 0.480384831129\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "totalSum = all_data['item_id'].map(all_data.groupby('item_id')['target'].sum())\n",
    "n_objects = all_data['item_id'].map(all_data.groupby('item_id')['target'].count())\n",
    "all_data['item_target_enc'] = (totalSum - all_data['target']) / (n_objects - 1)\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)\n",
    "grader.submit_tag('Leave-one-out_scheme', corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explained starting at 4:03 of [Regularization video](https://www.coursera.org/learn/competitive-data-science/lecture/LGYQ2/regularization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, implement smoothing scheme with $\\alpha = 100$. Use the formula from the first slide in the video and $0.3343$ as `globalmean`. Note that `nrows` is the number of objects that belong to a certain category (not the number of rows in the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48181987971\n",
      "Current answer for task Smoothing_scheme is: 0.48181987971\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "alpha = 100\n",
    "globalmean = 0.3343\n",
    "nrows = all_data.groupby('item_id')['target'].count()\n",
    "targetmean = all_data.groupby('item_id')['target'].mean()\n",
    "smooth = (targetmean*nrows + globalmean*alpha) / (nrows + alpha)\n",
    "all_data['item_target_enc'] = all_data['item_id'].map(smooth)\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)\n",
    "grader.submit_tag('Smoothing_scheme', corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Expanding mean scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explained starting at 5:50 of [Regularization video](https://www.coursera.org/learn/competitive-data-science/lecture/LGYQ2/regularization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally, implement the *expanding mean* scheme. It is basically already implemented for you in the video, but you can challenge yourself and try to implement it yourself. You will need [`cumsum`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.cumsum.html) and [`cumcount`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.GroupBy.cumcount.html) functions from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139255         0.0\n",
      "141495         0.0\n",
      "144968         0.0\n",
      "142661         0.0\n",
      "138947         0.0\n",
      "138948         0.0\n",
      "138949         0.0\n",
      "139247         0.0\n",
      "142672         0.0\n",
      "142065         0.0\n",
      "139208         0.0\n",
      "142670         0.0\n",
      "139207         0.0\n",
      "138950         0.0\n",
      "143764         0.0\n",
      "141505         0.0\n",
      "139199         0.0\n",
      "138952         0.0\n",
      "139176         0.0\n",
      "138951         0.0\n",
      "139177         0.0\n",
      "139178         0.0\n",
      "139179         0.0\n",
      "143769         0.0\n",
      "142671         0.0\n",
      "144539         0.0\n",
      "139180         0.0\n",
      "138953         0.0\n",
      "144265         0.0\n",
      "141744         0.0\n",
      "             ...  \n",
      "10772600    1209.0\n",
      "10770510     126.0\n",
      "10769953     108.0\n",
      "10769955    1664.0\n",
      "10768833     184.0\n",
      "10769961     420.0\n",
      "10770625     143.0\n",
      "10769956     695.0\n",
      "10771598    2807.0\n",
      "10767854    3441.0\n",
      "10768086    5271.0\n",
      "10768087    1191.0\n",
      "10768088    2089.0\n",
      "10767847     389.0\n",
      "10769954     260.0\n",
      "10767848    1707.0\n",
      "10767849     310.0\n",
      "10768089     104.0\n",
      "10770726     131.0\n",
      "10772844     187.0\n",
      "10771530     121.0\n",
      "10768090     351.0\n",
      "10769958     320.0\n",
      "10769959      59.0\n",
      "10769704       1.0\n",
      "10768834     699.0\n",
      "10769024      75.0\n",
      "10769690     493.0\n",
      "10771216     348.0\n",
      "10770511    1320.0\n",
      "Name: target, Length: 10913850, dtype: float64\n",
      "139255         0\n",
      "141495         0\n",
      "144968         0\n",
      "142661         0\n",
      "138947         0\n",
      "138948         0\n",
      "138949         0\n",
      "139247         0\n",
      "142672         0\n",
      "142065         0\n",
      "139208         0\n",
      "142670         0\n",
      "139207         0\n",
      "138950         0\n",
      "143764         0\n",
      "141505         0\n",
      "139199         0\n",
      "138952         0\n",
      "139176         0\n",
      "138951         0\n",
      "139177         0\n",
      "139178         0\n",
      "139179         0\n",
      "143769         0\n",
      "142671         0\n",
      "144539         0\n",
      "139180         0\n",
      "138953         0\n",
      "144265         0\n",
      "141744         0\n",
      "            ... \n",
      "10772600    1455\n",
      "10770510     899\n",
      "10769953     214\n",
      "10769955    1220\n",
      "10768833    1124\n",
      "10769961    1134\n",
      "10770625     898\n",
      "10769956     993\n",
      "10771598    1448\n",
      "10767854    1585\n",
      "10768086    1585\n",
      "10768087    1585\n",
      "10768088    1585\n",
      "10767847     171\n",
      "10769954     258\n",
      "10767848     258\n",
      "10767849     351\n",
      "10768089    1075\n",
      "10770726    1034\n",
      "10772844    1585\n",
      "10771530     498\n",
      "10768090    1585\n",
      "10769958     491\n",
      "10769959     536\n",
      "10769704      43\n",
      "10768834     448\n",
      "10769024     128\n",
      "10769690     398\n",
      "10771216    1175\n",
      "10770511    1220\n",
      "Length: 10913850, dtype: int64\n",
      "0.502524521108\n",
      "Current answer for task Expanding_mean_scheme is: 0.502524521108\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "cumsum = all_data.groupby('item_id')['target'].cumsum() - all_data['target']\n",
    "cumcnt = all_data.groupby('item_id').cumcount()\n",
    "\n",
    "print(cumsum)\n",
    "print(cumcnt)\n",
    "all_data['item_target_enc'] = cumsum/cumcnt\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)\n",
    "grader.submit_tag('Expanding_mean_scheme', corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authorization & Submission\n",
    "To submit assignment parts to Cousera platform, please, enter your e-mail and token into variables below. You can generate token on this programming assignment page. Note: Token expires 30 minutes after generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You want to submit these numbers:\n",
      "Task KFold_scheme: 0.41645907128\n",
      "Task Leave-one-out_scheme: 0.480384831129\n",
      "Task Smoothing_scheme: 0.48181987971\n",
      "Task Expanding_mean_scheme: 0.502524521108\n"
     ]
    }
   ],
   "source": [
    "STUDENT_EMAIL = \"klau@edu.hse.ru\"\n",
    "STUDENT_TOKEN = \"7oXJL8vz9UvwrmU9\"\n",
    "grader.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "grader.submit(STUDENT_EMAIL, STUDENT_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
